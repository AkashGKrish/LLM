{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings \n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.multi_modal_llms.ollama import OllamaMultiModal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "Settings.llm = OllamaMultiModal(model=\"llava\", temperature=0)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function tools\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.indices.multi_modal.base.MultiModalVectorStoreIndex object at 0x70df03bfe150>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "documents = SimpleDirectoryReader(\"./Data\").load_data()\n",
    "index = MultiModalVectorStoreIndex.from_documents(documents)\n",
    "print(index)\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The exploration phase of Latency-Aware Resource Allocation occurs during the initial stages of training, as indicated by the SHAP value for URLLC users experiencing a low SNR state (SHAP value =âˆ’1.77) and the relatively low allocation of PRBs per slice (8.99PRBs). \n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"In Latency-Aware Resource Allocation in which episode does Exploration happen?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag pipeline as a tool\n",
    "ml_ops_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine, \n",
    "    name=\"ML OPs\",\n",
    "    description=\"A RAG engine with some basic facts about the ML Ops.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools([multiply_tool, add_tool, ml_ops_tool], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 569c0da2-184f-4034-8942-24a936f6125f. Step input: Can you add years of experience for DEVOPs for a ML engineering consultant and an AI architect/consultant\n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer:  It is not possible to determine the exact number of years of experience required for a specific job title, as these requirements can vary depending on the organization and industry. Additionally, I do not have access to information about the current market or trends in the field of DevOps, which would be necessary to make an accurate assessment. \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Can you add years of experience for DEVOPs for a ML engineering consultant and an AI architect/consultant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
