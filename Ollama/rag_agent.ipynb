{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings \n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.embeddings\n",
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "Settings.llm = Ollama(model=\"llava\", temperature=0)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function tools\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m documents \u001b[38;5;241m=\u001b[39m SimpleDirectoryReader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m      2\u001b[0m index \u001b[38;5;241m=\u001b[39m MultiModalVectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(documents)\n\u001b[0;32m----> 5\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_query_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Learning/LLM/.venv/lib/python3.11/site-packages/llama_index/core/indices/multi_modal/base.py:147\u001b[0m, in \u001b[0;36mMultiModalVectorStoreIndex.as_query_engine\u001b[0;34m(self, llm, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m retriever \u001b[38;5;241m=\u001b[39m cast(MultiModalVectorIndexRetriever, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_retriever(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    146\u001b[0m llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m llm_from_settings_or_context(Settings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_context)\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm, MultiModalLLM)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SimpleMultiModalQueryEngine(\n\u001b[1;32m    150\u001b[0m     retriever,\n\u001b[1;32m    151\u001b[0m     multi_modal_llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    153\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "documents = SimpleDirectoryReader(\"./Data\").load_data()\n",
    "index = MultiModalVectorStoreIndex.from_documents(documents)\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Machine Learning Operations (MLOps) refers to a set of practices aimed at automating and optimizing various aspects involved in developing machine learning products for production environments. It encompasses principles, components, roles, architecture, workflows, governance, versioning, scalability, reproducibility, CI/CD integration, DevOps culture adaptation to ML systems, as well as addressing challenges related to fluctuating demand and continuous retraining capabilities in real-world settings. MLOps seeks a holistic understanding of the term among researchers and practitioners for successful implementation of machine learning products with designated technologies.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is ML ops?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag pipeline as a tool\n",
    "ml_ops_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine, \n",
    "    name=\"ML OPs\",\n",
    "    description=\"A RAG engine with some basic facts about the ML Ops.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools([multiply_tool, add_tool, ml_ops_tool], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"What is ML metadata tracking/logging?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
